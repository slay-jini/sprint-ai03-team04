{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af2c35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm # tqdm 임포트\n",
    "\n",
    "# =================================================================================\n",
    "# 0. 콜백 클래스 정의 (EarlyStopping)\n",
    "# =================================================================================\n",
    "# 이 클래스는 훈련을 효율적으로 관리하는 전문가용 기능입니다.\n",
    "class EarlyStopping:\n",
    "    \"\"\"검증 손실이 개선되지 않으면 훈련을 조기에 중단시킵니다.\"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 개선이 없다고 판단하기까지 기다릴 에폭 수.\n",
    "            min_delta (float): 개선으로 인정할 최소 변화량.\n",
    "            verbose (bool): 조기 중단 시 메시지를 출력할지 여부.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(f\"EarlyStopping: 검증 손실이 {self.patience} 에폭 동안 개선되지 않았습니다. 훈련을 중단합니다.\")\n",
    "                self.early_stop = True\n",
    "\n",
    "# 0. 콜백 클래스 정의 (CheckpointSaver 추가)\n",
    "class CheckpointSaver:\n",
    "    \"\"\"검증 손실을 기준으로 상위 K개의 모델만 저장하고 관리합니다.\"\"\"\n",
    "    def __init__(self, save_dir='checkpoints', top_k=3, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            save_dir (str): 체크포인트를 저장할 디렉토리.\n",
    "            top_k (int): 유지할 상위 모델의 개수.\n",
    "            verbose (bool): 모델 저장/삭제 시 메시지를 출력할지 여부.\n",
    "        \"\"\"\n",
    "        self.save_dir = save_dir\n",
    "        self.top_k = top_k\n",
    "        self.verbose = verbose\n",
    "        # (loss, filepath) 튜플을 저장할 리스트\n",
    "        self.checkpoints = []\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "\n",
    "    def __call__(self, val_loss, epoch, model):\n",
    "        # 파일명 생성 (Keras 스타일)\n",
    "        filename = f\"EPOCH({epoch+1:02d})-LOSS({val_loss:.4f}).pth\"\n",
    "        filepath = os.path.join(self.save_dir, filename)\n",
    "\n",
    "        # 현재 저장된 체크포인트가 K개 미만이거나,\n",
    "        # 현재 손실이 저장된 체크포인트 중 가장 나쁜(가장 큰) 손실보다 좋을 때만 저장\n",
    "        if len(self.checkpoints) < self.top_k or val_loss < self.checkpoints[-1][0]:\n",
    "            # 모델 저장\n",
    "            torch.save(model.state_dict(), filepath)\n",
    "            \n",
    "            # 리스트에 추가\n",
    "            self.checkpoints.append((val_loss, filepath))\n",
    "            \n",
    "            # 손실을 기준으로 오름차순 정렬 (가장 좋은 모델이 맨 앞에 오도록)\n",
    "            self.checkpoints.sort(key=lambda x: x[0])\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"  -> 체크포인트 저장: {filepath} (검증 손실: {val_loss:.4f})\")\n",
    "\n",
    "            # 만약 저장된 체크포인트가 K개를 초과하면, 가장 나쁜 모델 삭제\n",
    "            if len(self.checkpoints) > self.top_k:\n",
    "                worst_checkpoint = self.checkpoints.pop() # 가장 마지막 요소 (가장 나쁜 손실)\n",
    "                try:\n",
    "                    os.remove(worst_checkpoint[1])\n",
    "                    if self.verbose:\n",
    "                        print(f\"  -> 오래된 체크포인트 삭제: {worst_checkpoint[1]}\")\n",
    "                except OSError as e:\n",
    "                    print(f\"Error removing file {worst_checkpoint[1]}: {e}\")\n",
    "\n",
    "# =================================================================================\n",
    "# 1. 데이터셋 클래스 정의 (PillDataset)\n",
    "# =================================================================================\n",
    "class PillDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.annotation_paths = sorted(glob.glob(os.path.join(self.root, 'train_annotations', '**', '*.json'), recursive=True))\n",
    "        \n",
    "        self.categories = self._get_all_categories()\n",
    "        self.cat_to_id = {cat['name']: cat['id'] for cat in self.categories}\n",
    "        self.id_to_cat = {cat['id']: cat['name'] for cat in self.categories}\n",
    "        \n",
    "        self.class_ids = sorted(self.cat_to_id.values())\n",
    "        self.map_cat_id_to_label = {cat_id: i + 1 for i, cat_id in enumerate(self.class_ids)}\n",
    "        \n",
    "        print(f\"총 {len(self.annotation_paths)}개의 annotation 파일을 찾았습니다.\")\n",
    "        print(f\"총 {len(self.class_ids)}개의 고유한 클래스를 발견했습니다.\")\n",
    "\n",
    "    def _get_all_categories(self):\n",
    "        all_cats = {}\n",
    "        # tqdm을 사용해 카테고리 로딩 진행 상황을 보여줍니다.\n",
    "        for ann_path in tqdm(self.annotation_paths, desc=\"카테고리 정보 로딩 중\"):\n",
    "            with open(ann_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                if 'categories' in data:\n",
    "                    for cat in data['categories']:\n",
    "                        if cat['id'] not in all_cats:\n",
    "                            all_cats[cat['id']] = cat\n",
    "        return list(all_cats.values())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ann_path = self.annotation_paths[idx]\n",
    "        \n",
    "        with open(ann_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        image_info = data['images'][0]\n",
    "        img_path = os.path.join(self.root, 'train_images', image_info['file_name'])\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            # Colab 환경에서는 파일을 못찾으면 다음으로 넘어가는게 중요\n",
    "            return None \n",
    "\n",
    "        annotations = data['annotations']\n",
    "        # 유효한 어노테이션이 없는 경우 건너뛰기\n",
    "        if not annotations or not any(ann.get('bbox') for ann in annotations):\n",
    "            return None\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in annotations:\n",
    "            # bbox 정보가 없거나 유효하지 않은 어노테이션은 건너뜁니다.\n",
    "            if 'bbox' not in ann or not ann['bbox']:\n",
    "                continue\n",
    "            x_min, y_min, w, h = ann['bbox']\n",
    "            # bbox가 비정상적인 경우 건너뜁니다.\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "            x_max, y_max = x_min + w, y_min + h\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            \n",
    "            original_cat_id = ann['category_id']\n",
    "            labels.append(self.map_cat_id_to_label[original_cat_id])\n",
    "\n",
    "        # 유효한 박스가 하나도 없으면 이 데이터는 무시합니다.\n",
    "        if not boxes:\n",
    "            return None\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        # area, iscrowd 등 모델이 요구하는 다른 키들도 추가해줍니다.\n",
    "        target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            # torchvision v2 transform은 이미지와 타겟을 함께 받습니다.\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotation_paths)\n",
    "\n",
    "# =================================================================================\n",
    "# 2. 모델 인스턴스 생성 함수\n",
    "# =================================================================================\n",
    "def get_model_instance(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# =================================================================================\n",
    "# 3. 데이터 변환 및 로더를 위한 헬퍼 함수\n",
    "# =================================================================================\n",
    "def get_transform(train):\n",
    "    import torchvision.transforms.v2 as T\n",
    "    transforms = []\n",
    "    transforms.append(T.ToImage())\n",
    "    transforms.append(T.ToDtype(torch.float32, scale=True))\n",
    "    if train:\n",
    "        # 훈련 시에만 데이터 증강을 추가합니다.\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 배치 내의 None 데이터를 걸러냅니다.\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch: # 만약 배치가 비어있으면 None을 반환\n",
    "        return (None, None)\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# =================================================================================\n",
    "# 4. 메인 실행 블록\n",
    "# =================================================================================\n",
    "if __name__ == '__main__':\n",
    "    # --- 설정 변수 ---\n",
    "    # !!! Colab 사용 시, 이 경로를 Google Drive에 마운트된 경로로 변경하세요 !!!\n",
    "    # 예: ROOT_DIRECTORY = \"/content/drive/MyDrive/pill_project\"\n",
    "    # ROOT_DIRECTORY = \"./\" \n",
    "    ROOT_DIRECTORY = \"/kaggle/input/train-pill\" \n",
    "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    NUM_EPOCHS = 20 # Early Stopping을 테스트하기 위해 에폭 수를 늘립니다.\n",
    "    BATCH_SIZE = 4\n",
    "    \n",
    "    print(f\"사용할 장치: {DEVICE}\")\n",
    "\n",
    "    # --- 데이터셋 및 데이터로더 준비 ---\n",
    "    # 훈련 데이터셋 (증강 적용)\n",
    "    dataset_train = PillDataset(root=ROOT_DIRECTORY, transforms=get_transform(train=True))\n",
    "    # 검증 데이터셋 (증강 미적용)\n",
    "    dataset_valid = PillDataset(root=ROOT_DIRECTORY, transforms=get_transform(train=False))\n",
    "    \n",
    "    # 클래스 수 결정 (배경 포함)\n",
    "    num_classes = len(dataset_train.class_ids) + 1\n",
    "    \n",
    "    # 훈련/검증 데이터셋 분할\n",
    "    indices = torch.randperm(len(dataset_train)).tolist()\n",
    "    train_size = int(len(dataset_train) * 0.8)\n",
    "    train_subset = torch.utils.data.Subset(dataset_train, indices[:train_size])\n",
    "    valid_subset = torch.utils.data.Subset(dataset_valid, indices[train_size:])\n",
    "\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, collate_fn=collate_fn\n",
    "    )\n",
    "    data_loader_valid = torch.utils.data.DataLoader(\n",
    "        valid_subset, batch_size=1, shuffle=False, num_workers=2, collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # --- 모델 및 옵티마이저 준비 ---\n",
    "    model = get_model_instance(num_classes)\n",
    "    model.to(DEVICE)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    \n",
    "    # --- 콜백 및 변수 초기화 ---\n",
    "    early_stopper = EarlyStopping(patience=5, verbose=True)\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    # CheckpointSaver 인스턴스 생성 (상위 3개 모델 저장)\n",
    "    checkpoint_saver = CheckpointSaver(save_dir='/kaggle/working/checkpoints', top_k=3, verbose=True)\n",
    "\n",
    "    # --- 훈련 및 검증 루프 ---\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # 훈련\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        # tqdm을 사용한 훈련 루프\n",
    "        progress_bar_train = tqdm(data_loader_train, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [훈련]\")\n",
    "        for images, targets in progress_bar_train:\n",
    "            # collate_fn에서 배치가 비어있을 수 있음\n",
    "            if images is None:\n",
    "                continue\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += losses.item()\n",
    "            progress_bar_train.set_postfix(loss=losses.item()) # tqdm에 현재 손실 표시\n",
    "        \n",
    "        avg_train_loss = train_loss / len(data_loader_train)\n",
    "        \n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        # tqdm을 사용한 검증 루프\n",
    "        progress_bar_valid = tqdm(data_loader_valid, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [검증]\")\n",
    "        with torch.no_grad(): # 검증 시에는 그래디언트 계산 불필요\n",
    "            for images, targets in progress_bar_valid:\n",
    "                if images is None:\n",
    "                    continue\n",
    "                images = list(image.to(DEVICE) for image in images)\n",
    "                targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                # 검증 시에는 훈련 모드와 달리, 모델이 예측과 손실을 함께 반환하지 않을 수 있음.\n",
    "                # 이를 위해 모델을 훈련 모드로 잠시 바꾸고, 타겟을 함께 넣어 손실을 계산합니다.\n",
    "                model.train()\n",
    "                loss_dict = model(images, targets)\n",
    "                model.eval()\n",
    "\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                val_loss += losses.item()\n",
    "                progress_bar_valid.set_postfix(loss=losses.item())\n",
    "\n",
    "\n",
    "        avg_val_loss = val_loss / len(data_loader_valid)\n",
    "        print(f\"Epoch {epoch+1}: 훈련 손실 = {avg_train_loss:.4f}, 검증 손실 = {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # # 최고 성능 모델 저장\n",
    "        # if avg_val_loss < best_val_loss:\n",
    "        #     best_val_loss = avg_val_loss\n",
    "        #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "        #     print(f\"  -> 새로운 최고 성능 모델 저장! (검증 손실: {best_val_loss:.4f})\")\n",
    "        \n",
    "        # 최고 성능 모델 저장 로직을 CheckpointSaver 호출로 대체\n",
    "        checkpoint_saver(avg_val_loss, epoch, model)\n",
    "\n",
    "        # Early Stopping 체크\n",
    "        early_stopper(avg_val_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            break # 훈련 루프 탈출\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(\"훈련 종료!\")\n",
    "    print(f\"최고 검증 손실: {best_val_loss:.4f}\")\n",
    "    \n",
    "    print(\"최종 저장된 상위 모델들:\")\n",
    "    for loss, path in checkpoint_saver.checkpoints:\n",
    "        print(f\"  - {path} (검증 손실: {loss:.4f})\")\n",
    "\n",
    "\n",
    "print(\"훈련이 모두 종료되었습니다.\")\n",
    "print(f\"최고 검증 손실: {checkpoint_saver.checkpoints[0][0]:.4f}\") # CheckpointSaver 사용 시\n",
    "print(f\"최고 성능 모델은 '{checkpoint_saver.checkpoints[0][1]}'에 저장되었습니다.\")\n",
    "\n",
    "# =================================================================================\n",
    "# 5. mAP 평가 실행 블록\n",
    "# =================================================================================\n",
    "print(\"\\n--- 최고 성능 모델로 mAP 평가를 시작합니다 ---\")\n",
    "\n",
    "# mAP 계산을 위한 라이브러리 설치 확인\n",
    "try:\n",
    "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "except ImportError:\n",
    "    print(\"torchmetrics 라이브러리가 설치되지 않았습니다. 설치를 시작합니다.\")\n",
    "    # Colab 환경에서 pip 설치 실행\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchmetrics\"])\n",
    "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "\n",
    "# --- 최고 성능 모델 로드 ---\n",
    "# CheckpointSaver가 저장한 가장 좋은 모델의 경로를 가져옵니다.\n",
    "best_model_path = checkpoint_saver.checkpoints[0][1]\n",
    "# 모델 구조를 다시 만들고, 저장된 가중치를 불러옵니다.\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "# --- mAP 계산기 및 평가 데이터로더 준비 ---\n",
    "metric = MeanAveragePrecision(iou_type=\"bbox\", iou_thresholds=[0.5])\n",
    "# 평가에는 검증 데이터셋(valid_subset)을 사용합니다.\n",
    "data_loader_eval = torch.utils.data.DataLoader(\n",
    "    valid_subset, batch_size=4, shuffle=False, num_workers=2, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "model.eval() # 모델을 평가 모드로 설정\n",
    "with torch.no_grad():\n",
    "    progress_bar = tqdm(data_loader_eval, desc=\"mAP 계산 중\")\n",
    "    for images, targets in progress_bar:\n",
    "        if images is None:\n",
    "            continue\n",
    "        \n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        preds = []\n",
    "        for output in outputs:\n",
    "            preds.append({\n",
    "                \"boxes\": output[\"boxes\"].cpu(),\n",
    "                \"scores\": output[\"scores\"].cpu(),\n",
    "                \"labels\": output[\"labels\"].cpu(),\n",
    "            })\n",
    "\n",
    "        target_formatted = []\n",
    "        for t in targets:\n",
    "            target_formatted.append({\n",
    "                \"boxes\": t[\"boxes\"].cpu(),\n",
    "                \"labels\": t[\"labels\"].cpu(),\n",
    "            })\n",
    "\n",
    "        metric.update(preds, target_formatted)\n",
    "\n",
    "# --- 최종 결과 출력 ---\n",
    "results = metric.compute()\n",
    "print(\"\\n--- 최종 mAP@0.5 결과 ---\")\n",
    "print(f\"  mAP: {results['map']:.4f}\")\n",
    "print(f\"  mAP@.50 (대회 기준): {results['map_50']:.4f}\") # IoU 0.50 에서의 mAP\n",
    "print(f\"  mAP (small): {results['map_small']:.4f}\")\n",
    "print(f\"  mAP (medium): {results['map_medium']:.4f}\")\n",
    "print(f\"  mAP (large): {results['map_large']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
