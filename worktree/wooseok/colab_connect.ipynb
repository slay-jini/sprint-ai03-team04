{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc697ea",
   "metadata": {},
   "source": [
    "# Google Colabì—ì„œ Git Cloneì„ í†µí•œ í”„ë¡œì íŠ¸ ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Google Colabì—ì„œ GitHub ë¦¬í¬ì§€í† ë¦¬ë¥¼ í´ë¡ í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë¡œì»¬ ê°œë°œ í™˜ê²½ ì—†ì´ë„ Colabì˜ GPU ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a3640",
   "metadata": {},
   "source": [
    "## 1. Colab í™˜ê²½ ì„¤ì •\n",
    "\n",
    "Google Colabì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ê¸°ë³¸ ì„¤ì •:\n",
    "\n",
    "1. **ëŸ°íƒ€ì„ íƒ€ì… ì„¤ì •**\n",
    "   - ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPU ì„ íƒ\n",
    "   - ê³ ì‚¬ì–‘ RAM ì„ íƒ (í•„ìš”ì‹œ)\n",
    "\n",
    "2. **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**\n",
    "   - PyTorch, torchvision ë“± ML ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "   - ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "3. **Google Drive ì—°ê²°** (ì„ íƒì‚¬í•­)\n",
    "   - ë°ì´í„°ì…‹ì´ Driveì— ì €ì¥ëœ ê²½ìš°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e32248",
   "metadata": {},
   "source": [
    "## 2. GitHub ë¦¬í¬ì§€í† ë¦¬ ë¸Œëœì¹˜ í´ë¡ \n",
    "\n",
    "**ê°œë°œ ì¤‘ì¸ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ íŠ¹ì • ë¸Œëœì¹˜ì—ì„œ í´ë¡ **:\n",
    "\n",
    "1. **ë¸Œëœì¹˜ í´ë¡  ì˜µì…˜**:\n",
    "   - íŠ¹ì • ë¸Œëœì¹˜ ì§ì ‘ í´ë¡ : `git clone -b branch_name`\n",
    "   - ëª¨ë“  ë¸Œëœì¹˜ í´ë¡  í›„ ì²´í¬ì•„ì›ƒ\n",
    "   - í˜„ì¬ ê°œë°œ ë¸Œëœì¹˜: `feature/wooseok-baseline-v0`\n",
    "\n",
    "2. **ë¸Œëœì¹˜ í™•ì¸ ë° ì „í™˜**:\n",
    "   - í˜„ì¬ ë¸Œëœì¹˜ í™•ì¸\n",
    "   - ë‹¤ë¥¸ ë¸Œëœì¹˜ë¡œ ì „í™˜\n",
    "   - ìµœì‹  ë³€ê²½ì‚¬í•­ ì—…ë°ì´íŠ¸\n",
    "\n",
    "3. **ì˜ì¡´ì„± ì„¤ì¹˜**:\n",
    "   - í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "   - í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25547588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install torch torchvision pillow\n",
    "\n",
    "# 2. ê°œë°œ ì¤‘ì¸ ë¸Œëœì¹˜ì—ì„œ ì§ì ‘ í´ë¡  (ê¶Œì¥)\n",
    "BRANCH_NAME = \"feature/wooseok-baseline-v0\"  # í˜„ì¬ ê°œë°œ ë¸Œëœì¹˜\n",
    "print(f\"ğŸŒ¿ í´ë¡ í•  ë¸Œëœì¹˜: {BRANCH_NAME}\")\n",
    "\n",
    "!git clone -b {BRANCH_NAME} https://github.com/slay-jini/sprint-ai03-team04.git\n",
    "\n",
    "# 3. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "import os\n",
    "os.chdir('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "\n",
    "# 4. ë¸Œëœì¹˜ í™•ì¸\n",
    "print(\"\\nğŸ” í˜„ì¬ ë¸Œëœì¹˜ í™•ì¸:\")\n",
    "!git branch -a\n",
    "!git status\n",
    "\n",
    "# 5. í˜„ì¬ ë””ë ‰í† ë¦¬ ë° íŒŒì¼ í™•ì¸\n",
    "print(f\"\\nğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "print(\"\\nğŸ“‹ í”„ë¡œì íŠ¸ íŒŒì¼ ëª©ë¡:\")\n",
    "!ls -la\n",
    "\n",
    "# 6. GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "import torch\n",
    "print(f\"\\nğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU ëª¨ë¸: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ì•ˆ ë°©ë²•: ë‹¤ë¥¸ ë¸Œëœì¹˜ë¡œ ì „í™˜í•˜ê±°ë‚˜ ìµœì‹  ë³€ê²½ì‚¬í•­ ì—…ë°ì´íŠ¸\n",
    "\n",
    "# ì˜µì…˜ 1: ì´ë¯¸ í´ë¡ ëœ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ë¸Œëœì¹˜ë¡œ ì „í™˜\n",
    "def switch_branch(branch_name):\n",
    "    \"\"\"ë‹¤ë¥¸ ë¸Œëœì¹˜ë¡œ ì „í™˜\"\"\"\n",
    "    print(f\"ğŸ”„ ë¸Œëœì¹˜ ì „í™˜: {branch_name}\")\n",
    "    !git checkout {branch_name}\n",
    "    !git pull origin {branch_name}\n",
    "    print(f\"âœ… {branch_name} ë¸Œëœì¹˜ë¡œ ì „í™˜ ì™„ë£Œ\")\n",
    "\n",
    "# ì˜µì…˜ 2: ëª¨ë“  ë¸Œëœì¹˜ í™•ì¸\n",
    "def list_all_branches():\n",
    "    \"\"\"ëª¨ë“  ë¸Œëœì¹˜ ëª©ë¡ í™•ì¸\"\"\"\n",
    "    print(\"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œëœì¹˜ ëª©ë¡:\")\n",
    "    !git branch -r\n",
    "\n",
    "# ì˜µì…˜ 3: í˜„ì¬ ë¸Œëœì¹˜ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸\n",
    "def update_current_branch():\n",
    "    \"\"\"í˜„ì¬ ë¸Œëœì¹˜ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸\"\"\"\n",
    "    current_branch = !git branch --show-current\n",
    "    branch_name = current_branch[0].strip() if current_branch else \"main\"\n",
    "    print(f\"ğŸ”„ í˜„ì¬ ë¸Œëœì¹˜ ì—…ë°ì´íŠ¸: {branch_name}\")\n",
    "    !git pull origin {branch_name}\n",
    "    print(\"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)\n",
    "# list_all_branches()\n",
    "# switch_branch(\"main\")  # main ë¸Œëœì¹˜ë¡œ ì „í™˜\n",
    "# update_current_branch()  # í˜„ì¬ ë¸Œëœì¹˜ ì—…ë°ì´íŠ¸\n",
    "\n",
    "print(\"ğŸ› ï¸  ë¸Œëœì¹˜ ê´€ë¦¬ í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(\"ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜:\")\n",
    "print(\"- list_all_branches(): ëª¨ë“  ë¸Œëœì¹˜ ëª©ë¡ í™•ì¸\")\n",
    "print(\"- switch_branch('ë¸Œëœì¹˜ëª…'): ë‹¤ë¥¸ ë¸Œëœì¹˜ë¡œ ì „í™˜\")\n",
    "print(\"- update_current_branch(): í˜„ì¬ ë¸Œëœì¹˜ ì—…ë°ì´íŠ¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5e578",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„°ì…‹ ì„¤ì • ë° ì¤€ë¹„\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”**: í˜„ì¬ ë¸Œëœì¹˜ì—ì„œëŠ” `dataset/` í´ë”ê°€ `.gitignore`ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. **ë°ì´í„°ì…‹ ì—…ë¡œë“œ**:\n",
    "   - Google Drive ë§ˆìš´íŠ¸ ë˜ëŠ” ì§ì ‘ ì—…ë¡œë“œ\n",
    "   - ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (Gitì—ì„œ ì œì™¸ë¨)\n",
    "   - íŒŒì¼ êµ¬ì¡° í™•ì¸\n",
    "\n",
    "2. **ì„¤ì • íŒŒì¼ ìˆ˜ì •**:\n",
    "   - config.pyì—ì„œ ê²½ë¡œ ì„¤ì •\n",
    "   - ë°°ì¹˜ í¬ê¸° ë° í•™ìŠµ íŒŒë¼ë¯¸í„° ì¡°ì •\n",
    "   - ë¸Œëœì¹˜ë³„ ì„¤ì • ì°¨ì´ í™•ì¸\n",
    "\n",
    "3. **ë¸Œëœì¹˜ë³„ ì°¨ì´ì **:\n",
    "   - ê°œë°œ ë¸Œëœì¹˜ì˜ ìµœì‹  ê¸°ëŠ¥ ì‚¬ìš©\n",
    "   - ì‹¤í—˜ì  ì½”ë“œ í¬í•¨ ê°€ëŠ¥ì„±\n",
    "   - main ë¸Œëœì¹˜ ëŒ€ë¹„ ì¶”ê°€ ê¸°ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. .gitignore í™•ì¸ (dataset í´ë” ì œì™¸ ì—¬ë¶€)\n",
    "print(\"ğŸ“‹ .gitignore íŒŒì¼ í™•ì¸:\")\n",
    "!cat /content/sprint-ai03-team04/.gitignore | grep -E \"(dataset|data)\" || echo \"dataset ê´€ë ¨ í•­ëª© ì—†ìŒ\"\n",
    "\n",
    "# 2. Google Drive ë§ˆìš´íŠ¸ (ë°ì´í„°ì…‹ì´ Driveì— ìˆëŠ” ê²½ìš°)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
    "import os\n",
    "\n",
    "# âš ï¸ ì¤‘ìš”: dataset í´ë”ê°€ .gitignoreì— í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë³„ë„ë¡œ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "print(\"\\nğŸš¨ ë°ì´í„°ì…‹ ì¤€ë¹„ ë°©ë²•:\")\n",
    "print(\"1. Google Driveì—ì„œ ë°ì´í„°ì…‹ì„ ë³µì‚¬í•˜ê±°ë‚˜\")\n",
    "print(\"2. ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”\")\n",
    "\n",
    "# ì˜µì…˜ 1: Google Driveì—ì„œ ë°ì´í„°ì…‹ ë³µì‚¬\n",
    "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/your_dataset\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "PROJECT_DATASET_PATH = \"/content/sprint-ai03-team04/worktree/wooseok/dataset\"\n",
    "\n",
    "# ì˜µì…˜ 2: ì§ì ‘ ì—…ë¡œë“œí•œ ê²½ìš°ì˜ ë°ì´í„°ì…‹ ê²½ë¡œ\n",
    "DATASET_PATH = \"/content/dataset\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "print(f\"\\nğŸ“ ë°ì´í„°ì…‹ ê²½ë¡œ ì˜µì…˜:\")\n",
    "print(f\"1. Google Drive: {DRIVE_DATASET_PATH}\")\n",
    "print(f\"2. í”„ë¡œì íŠ¸ ë‚´: {PROJECT_DATASET_PATH}\")\n",
    "print(f\"3. ì§ì ‘ ì—…ë¡œë“œ: {DATASET_PATH}\")\n",
    "\n",
    "# 4. ì‚¬ìš©í•  ë°ì´í„°ì…‹ ê²½ë¡œ ì„ íƒ (ì•„ë˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ)\n",
    "SELECTED_DATASET = DRIVE_DATASET_PATH  # ì‹¤ì œ ìƒí™©ì— ë§ê²Œ ë³€ê²½\n",
    "\n",
    "# 5. ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸\n",
    "if os.path.exists(SELECTED_DATASET):\n",
    "    print(f\"\\nâœ… ë°ì´í„°ì…‹ ê²½ë¡œ ë°œê²¬: {SELECTED_DATASET}\")\n",
    "    print(\"ğŸ“‹ ë°ì´í„°ì…‹ êµ¬ì¡°:\")\n",
    "    !ls -la {SELECTED_DATASET}\n",
    "    \n",
    "    # train.json íŒŒì¼ í™•ì¸\n",
    "    if os.path.exists(f\"{SELECTED_DATASET}/train.json\"):\n",
    "        print(f\"âœ… train.json íŒŒì¼ ë°œê²¬\")\n",
    "    else:\n",
    "        print(\"âŒ train.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "    if os.path.exists(f\"{SELECTED_DATASET}/images/train\"):\n",
    "        img_count = len(os.listdir(f\"{SELECTED_DATASET}/images/train\"))\n",
    "        print(f\"âœ… ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ë°œê²¬ ({img_count}ê°œ íŒŒì¼)\")\n",
    "    else:\n",
    "        print(\"âŒ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"\\nâŒ ë°ì´í„°ì…‹ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SELECTED_DATASET}\")\n",
    "    print(\"ğŸ“‹ ë°ì´í„°ì…‹ ì¤€ë¹„ ê°€ì´ë“œ:\")\n",
    "    print(\"1. Google Driveì— ë°ì´í„°ì…‹ ì—…ë¡œë“œ\")\n",
    "    print(\"2. ê²½ë¡œë¥¼ SELECTED_DATASET ë³€ìˆ˜ì— ì„¤ì •\")\n",
    "    print(\"3. ë˜ëŠ” Colabì— ì§ì ‘ ì—…ë¡œë“œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bae6eb",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "í”„ë¡œì íŠ¸ ì„¤ì •ì´ ì™„ë£Œë˜ë©´ í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ë°ì´í„°ì…‹ ìƒì„±**:\n",
    "   - ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±\n",
    "   - ë°ì´í„° ë¡œë” ì„¤ì •\n",
    "   - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í™•ì¸\n",
    "\n",
    "2. **í•™ìŠµ ì‹¤í–‰**:\n",
    "   - ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
    "   - í•™ìŠµ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§\n",
    "   - ê²°ê³¼ ì €ì¥\n",
    "\n",
    "3. **ì£¼ì˜ì‚¬í•­**:\n",
    "   - Colab ì„¸ì…˜ ì‹œê°„ ì œí•œ (12ì‹œê°„)\n",
    "   - ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ì²´í¬í¬ì¸íŠ¸)\n",
    "   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa317b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì„¤ì • íŒŒì¼ í™•ì¸ ë° ìˆ˜ì •\n",
    "import sys\n",
    "sys.path.append('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "\n",
    "# config.py ë‚´ìš© í™•ì¸\n",
    "try:\n",
    "    from config import cfg\n",
    "    print(\"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì„±ê³µ\")\n",
    "    print(f\"ë””ë°”ì´ìŠ¤: {cfg.DEVICE}\")\n",
    "    print(f\"ë°°ì¹˜ í¬ê¸°: {cfg.BATCH_SIZE}\")\n",
    "    print(f\"ì—í¬í¬: {cfg.EPOCHS}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "print(f\"\\n=== ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸ ===\")\n",
    "print(f\"RAM ì‚¬ìš©ëŸ‰: {psutil.virtual_memory().percent}%\")\n",
    "print(f\"ì‚¬ìš© ê°€ëŠ¥í•œ RAM: {psutil.virtual_memory().available / (1024**3):.2f} GB\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "    print(f\"GPU ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated(0) / (1024**3):.2f} GB\")\n",
    "\n",
    "print(\"\\n=== í™˜ê²½ ì„¤ì • ì™„ë£Œ ===\")\n",
    "print(\"ì´ì œ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê³  í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c05d0",
   "metadata": {},
   "source": [
    "## ê°œë°œ ë¸Œëœì¹˜ì—ì„œ ë°ì´í„°ì…‹ ìƒì„± ë° í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "**ğŸŒ¿ í˜„ì¬ ë¸Œëœì¹˜**: `feature/wooseok-baseline-v0`\n",
    "\n",
    "ì•„ë˜ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë°œ ì¤‘ì¸ ë¸Œëœì¹˜ì—ì„œ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê³  í•™ìŠµì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "main ë¸Œëœì¹˜ì— mergeí•˜ê¸° ì „ì— ì—¬ê¸°ì„œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colabì—ì„œ í´ë¡ í•œ í”„ë¡œì íŠ¸ë¡œ ë°ì´í„°ì…‹ ìƒì„± ë° í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "# 1. ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸ ë° ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "os.chdir('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "sys.path.append('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "\n",
    "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
    "DATASET_JSON = \"/content/dataset/train.json\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "DATASET_IMAGES = \"/content/dataset/images/train\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "# ë˜ëŠ” Google Driveì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²½ìš°:\n",
    "# DATASET_JSON = \"/content/drive/MyDrive/your_dataset/train.json\"\n",
    "# DATASET_IMAGES = \"/content/drive/MyDrive/your_dataset/images/train\"\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ìƒì„±\n",
    "try:\n",
    "    from dataset import create_colab_dataset\n",
    "    \n",
    "    dataset = create_colab_dataset(\n",
    "        json_path=DATASET_JSON,\n",
    "        img_dir=DATASET_IMAGES\n",
    "    )\n",
    "    \n",
    "    if dataset is not None:\n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ: {len(dataset)} ê°œì˜ ìƒ˜í”Œ\")\n",
    "        \n",
    "        # 4. í•™ìŠµ ì‹¤í–‰\n",
    "        from train import train_with_dataset\n",
    "        print(\"ğŸš€ í•™ìŠµ ì‹œì‘...\")\n",
    "        train_with_dataset(dataset)\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨\")\n",
    "        print(\"ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "        print(f\"JSON íŒŒì¼: {DATASET_JSON}\")\n",
    "        print(f\"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {DATASET_IMAGES}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"í”„ë¡œì íŠ¸ íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ í´ë¡ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€ì•ˆ ë°©ë²•: ë‹¨ê³„ë³„ë¡œ í•™ìŠµ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "# 1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "sys.path.append('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "\n",
    "print(\"ğŸ“ í”„ë¡œì íŠ¸ íŒŒì¼ í™•ì¸:\")\n",
    "required_files = ['train.py', 'dataset.py', 'config.py', 'trainer.py']\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"âœ… {file}\")\n",
    "    else:\n",
    "        print(f\"âŒ {file} - íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ íŒŒì¼ ì§ì ‘ ì§€ì •\n",
    "# Google Drive ë˜ëŠ” ì—…ë¡œë“œëœ ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”\n",
    "json_path = \"/content/drive/MyDrive/your_dataset/train.json\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "img_dir = \"/content/drive/MyDrive/your_dataset/images/train\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "print(f\"\\nğŸ“Š ë°ì´í„°ì…‹ ê²½ë¡œ:\")\n",
    "print(f\"JSON: {json_path}\")\n",
    "print(f\"Images: {img_dir}\")\n",
    "\n",
    "# 3. ê²½ë¡œ ì¡´ì¬ í™•ì¸\n",
    "json_exists = os.path.exists(json_path)\n",
    "img_exists = os.path.exists(img_dir)\n",
    "\n",
    "print(f\"\\nğŸ“‹ ê²½ë¡œ í™•ì¸:\")\n",
    "print(f\"JSON íŒŒì¼ ì¡´ì¬: {json_exists}\")\n",
    "print(f\"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì¡´ì¬: {img_exists}\")\n",
    "\n",
    "if json_exists and img_exists:\n",
    "    print(f\"ì´ë¯¸ì§€ ê°œìˆ˜: {len(os.listdir(img_dir))}\")\n",
    "    \n",
    "    # 4. ë°ì´í„°ì…‹ ìƒì„± ë° í•™ìŠµ\n",
    "    try:\n",
    "        from dataset import PillDetectionDataset\n",
    "        from train import train_with_dataset\n",
    "        \n",
    "        dataset = PillDetectionDataset(\n",
    "            json_file=json_path,\n",
    "            img_dir=img_dir\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset)} ìƒ˜í”Œ\")\n",
    "        \n",
    "        # í•™ìŠµ ì‹¤í–‰\n",
    "        print(\"ğŸš€ í•™ìŠµ ì‹œì‘...\")\n",
    "        train_with_dataset(dataset)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í•™ìŠµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "    print(\"Google Driveë¥¼ ë§ˆìš´íŠ¸í–ˆëŠ”ì§€, ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d3a9f",
   "metadata": {},
   "source": [
    "## 5. ë¸Œëœì¹˜ ê°œë°œ ë° ë¬¸ì œ í•´ê²°\n",
    "\n",
    "### ğŸŒ¿ ë¸Œëœì¹˜ ê´€ë ¨ íŒ\n",
    "\n",
    "1. **í˜„ì¬ ë¸Œëœì¹˜ í™•ì¸**:\n",
    "   - `!git branch --show-current`\n",
    "   - `!git status`\n",
    "\n",
    "2. **ë¸Œëœì¹˜ ì „í™˜**:\n",
    "   - `!git checkout main` (main ë¸Œëœì¹˜ë¡œ)\n",
    "   - `!git checkout feature/wooseok-baseline-v0` (ê°œë°œ ë¸Œëœì¹˜ë¡œ)\n",
    "\n",
    "3. **ìµœì‹  ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°**:\n",
    "   - `!git pull origin feature/wooseok-baseline-v0`\n",
    "\n",
    "### ğŸ“ ë°ì´í„°ì…‹ ê´€ë¦¬\n",
    "\n",
    "1. **Gitì—ì„œ ì œì™¸ëœ íŒŒì¼ë“¤**:\n",
    "   - `dataset/` í´ë” (`.gitignore`ì— í¬í•¨)\n",
    "   - `__pycache__/` í´ë”\n",
    "   - ë¡œê·¸ íŒŒì¼, ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸\n",
    "\n",
    "2. **ë°ì´í„°ì…‹ ì¤€ë¹„ ë°©ë²•**:\n",
    "   - Google Drive ì—…ë¡œë“œ í›„ ë§ˆìš´íŠ¸\n",
    "   - ì§ì ‘ Colabì— ì—…ë¡œë“œ\n",
    "   - ì™¸ë¶€ ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "### ğŸš¨ ê°œë°œ ë¸Œëœì¹˜ ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "- ê°œë°œ ì¤‘ì¸ ì½”ë“œë¡œ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ê°€ëŠ¥\n",
    "- ì‹¤í—˜ì  ê¸°ëŠ¥ í¬í•¨ ê°€ëŠ¥ì„±\n",
    "- main ë¸Œëœì¹˜ ëŒ€ë¹„ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ\n",
    "- í…ŒìŠ¤íŠ¸ í›„ ì´ìƒ ì—†ìœ¼ë©´ mainìœ¼ë¡œ merge\n",
    "\n",
    "### ğŸ”„ merge ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] ì½”ë“œ ì •ìƒ ì‹¤í–‰ í™•ì¸\n",
    "- [ ] ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
    "- [ ] ì˜¤ë¥˜ ë©”ì‹œì§€ ì—†ìŒ\n",
    "- [ ] ì„±ëŠ¥ ì €í•˜ ì—†ìŒ\n",
    "- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ í•„ìš”ì‹œ ë°˜ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d279a5",
   "metadata": {},
   "source": [
    "## ğŸš¨ CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ í•´ê²° ë°©ë²•\n",
    "\n",
    "**\"CUDA error: an illegal memory access was encountered\"** ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:\n",
    "\n",
    "### ğŸ“‹ ì¼ë°˜ì ì¸ ì›ì¸ë“¤:\n",
    "1. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±** - ë°°ì¹˜ í¬ê¸°ê°€ ë„ˆë¬´ í¼\n",
    "2. **í…ì„œ í¬ê¸° ë¶ˆì¼ì¹˜** - ëª¨ë¸ ì…ë ¥ê³¼ ì‹¤ì œ ë°ì´í„° í¬ê¸° ì°¨ì´\n",
    "3. **CUDA ë²„ì „ í˜¸í™˜ì„±** - PyTorchì™€ CUDA ë²„ì „ ë¶ˆì¼ì¹˜\n",
    "4. **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** - ì´ì „ ì‹¤í–‰ì—ì„œ ë‚¨ì€ GPU ë©”ëª¨ë¦¬\n",
    "\n",
    "### ğŸ”§ í•´ê²° ë°©ë²•ë“¤:\n",
    "1. **GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œì‘**\n",
    "2. **ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°**\n",
    "3. **ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”**\n",
    "4. **ë°ì´í„° ë¡œë” worker ìˆ˜ ì¡°ì •**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7119c7a",
   "metadata": {},
   "source": [
    "## ğŸ”„ PyTorch ìˆœí™˜ Import ì˜¤ë¥˜ í•´ê²°\n",
    "\n",
    "**\"partially initialized module 'torch._dynamo' has no attribute 'config'\"** ì˜¤ë¥˜ í•´ê²°:\n",
    "\n",
    "### ğŸ“‹ ì›ì¸ ë¶„ì„:\n",
    "1. **ìˆœí™˜ Import** - í”„ë¡œì íŠ¸ íŒŒì¼ë“¤ ê°„ì˜ circular import\n",
    "2. **PyTorch ë²„ì „ ë¬¸ì œ** - ë²„ì „ í˜¸í™˜ì„± ì´ìŠˆ\n",
    "3. **ëª¨ë“ˆ ì´ˆê¸°í™” ì˜¤ë¥˜** - ëª¨ë“ˆì´ ì™„ì „íˆ ë¡œë“œë˜ê¸° ì „ ì ‘ê·¼\n",
    "4. **ìºì‹œëœ ëª¨ë“ˆ** - ì´ì „ ì‹¤í–‰ì˜ ì˜ëª»ëœ ìºì‹œ\n",
    "\n",
    "### ğŸ”§ í•´ê²° ë°©ë²•:\n",
    "1. **íŒŒì´ì¬ ëª¨ë“ˆ ìºì‹œ ì •ë¦¬**\n",
    "2. **Import ìˆœì„œ ì¡°ì •**\n",
    "3. **PyTorch ì¬ì„¤ì¹˜**\n",
    "4. **ëŸ°íƒ€ì„ ì¬ì‹œì‘**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba87857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch ìˆœí™˜ Import ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ì¢…í•© ì†”ë£¨ì…˜\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import gc\n",
    "\n",
    "def clean_python_modules():\n",
    "    \"\"\"Python ëª¨ë“ˆ ìºì‹œ ì •ë¦¬\"\"\"\n",
    "    print(\"ğŸ§¹ Python ëª¨ë“ˆ ìºì‹œ ì •ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    # 1. í”„ë¡œì íŠ¸ ê´€ë ¨ ëª¨ë“ˆ ì œê±°\n",
    "    modules_to_remove = []\n",
    "    for module_name in list(sys.modules.keys()):\n",
    "        if any(keyword in module_name for keyword in ['config', 'dataset', 'train', 'trainer', 'torch._dynamo']):\n",
    "            modules_to_remove.append(module_name)\n",
    "    \n",
    "    for module_name in modules_to_remove:\n",
    "        if module_name in sys.modules:\n",
    "            del sys.modules[module_name]\n",
    "            print(f\"  âœ… {module_name} ëª¨ë“ˆ ì œê±°\")\n",
    "    \n",
    "    # 2. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜\n",
    "    gc.collect()\n",
    "    print(\"âœ… ëª¨ë“ˆ ìºì‹œ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "def fix_pytorch_import():\n",
    "    \"\"\"PyTorch Import ë¬¸ì œ í•´ê²°\"\"\"\n",
    "    print(\"ğŸ”§ PyTorch Import ë¬¸ì œ í•´ê²° ì¤‘...\")\n",
    "    \n",
    "    # 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "    os.environ['PYTHONDONTWRITEBYTECODE'] = '1'  # .pyc íŒŒì¼ ìƒì„± ë°©ì§€\n",
    "    \n",
    "    # 2. PyTorch ëª¨ë“ˆ ê°•ì œ ì¬ë¡œë“œ\n",
    "    try:\n",
    "        import torch\n",
    "        importlib.reload(torch)\n",
    "        print(\"âœ… PyTorch ëª¨ë“ˆ ì¬ë¡œë“œ ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ PyTorch ì¬ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 3. torch._dynamo ì§ì ‘ í™•ì¸\n",
    "    try:\n",
    "        import torch._dynamo\n",
    "        if hasattr(torch._dynamo, 'config'):\n",
    "            print(\"âœ… torch._dynamo.config ì •ìƒ ì ‘ê·¼ ê°€ëŠ¥\")\n",
    "        else:\n",
    "            print(\"âŒ torch._dynamo.config ì†ì„± ì—†ìŒ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ torch._dynamo ì ‘ê·¼ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "def check_circular_imports():\n",
    "    \"\"\"ìˆœí™˜ import í™•ì¸\"\"\"\n",
    "    print(\"ğŸ” ìˆœí™˜ import í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "    project_dir = '/content/sprint-ai03-team04/worktree/wooseok'\n",
    "    \n",
    "    if os.path.exists(project_dir):\n",
    "        os.chdir(project_dir)\n",
    "        \n",
    "        # í”„ë¡œì íŠ¸ íŒŒì¼ë“¤ í™•ì¸\n",
    "        project_files = ['config.py', 'dataset.py', 'train.py', 'trainer.py']\n",
    "        \n",
    "        for file in project_files:\n",
    "            if os.path.exists(file):\n",
    "                print(f\"ğŸ“„ {file} íŒŒì¼ ì¡´ì¬\")\n",
    "                \n",
    "                # ê° íŒŒì¼ì˜ import êµ¬ë¬¸ í™•ì¸\n",
    "                try:\n",
    "                    with open(file, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                        imports = [line.strip() for line in content.split('\\n') \n",
    "                                 if line.strip().startswith('import ') or line.strip().startswith('from ')]\n",
    "                        \n",
    "                        print(f\"  Import êµ¬ë¬¸ ({len(imports)}ê°œ):\")\n",
    "                        for imp in imports[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ\n",
    "                            print(f\"    {imp}\")\n",
    "                        if len(imports) > 5:\n",
    "                            print(f\"    ... ë° {len(imports) - 5}ê°œ ë”\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "            else:\n",
    "                print(f\"âŒ {file} íŒŒì¼ ì—†ìŒ\")\n",
    "    else:\n",
    "        print(f\"âŒ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {project_dir}\")\n",
    "\n",
    "def reinstall_pytorch():\n",
    "    \"\"\"PyTorch ì¬ì„¤ì¹˜\"\"\"\n",
    "    print(\"ğŸ”„ PyTorch ì¬ì„¤ì¹˜ ì¤‘...\")\n",
    "    \n",
    "    # í˜„ì¬ PyTorch ë²„ì „ í™•ì¸\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"í˜„ì¬ PyTorch ë²„ì „: {torch.__version__}\")\n",
    "        print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "    except:\n",
    "        print(\"PyTorch ë²„ì „ í™•ì¸ ë¶ˆê°€\")\n",
    "    \n",
    "    # ì¬ì„¤ì¹˜ ëª…ë ¹ì–´ ì œê³µ\n",
    "    print(\"\\nğŸ› ï¸  PyTorch ì¬ì„¤ì¹˜ ëª…ë ¹ì–´:\")\n",
    "    print(\"ë‹¤ìŒ ì…€ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "    print(\"!pip uninstall torch torchvision torchaudio -y\")\n",
    "    print(\"!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸš¨ PyTorch ìˆœí™˜ Import ì˜¤ë¥˜ í•´ê²° ì‹œì‘\")\n",
    "clean_python_modules()\n",
    "fix_pytorch_import()\n",
    "check_circular_imports()\n",
    "reinstall_pytorch()\n",
    "\n",
    "print(\"\\nğŸ¯ ê¶Œì¥ í•´ê²° ìˆœì„œ:\")\n",
    "print(\"1. ëŸ°íƒ€ì„ ì¬ì‹œì‘ (ê°€ì¥ íš¨ê³¼ì )\")\n",
    "print(\"2. PyTorch ì¬ì„¤ì¹˜\")\n",
    "print(\"3. í”„ë¡œì íŠ¸ íŒŒì¼ import êµ¬ì¡° í™•ì¸\")\n",
    "print(\"4. ì•ˆì „í•œ import ìˆœì„œë¡œ ì¬ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32341928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch ì¬ì„¤ì¹˜ (ìˆœí™˜ import ì˜¤ë¥˜ í•´ê²°)\n",
    "\n",
    "print(\"ğŸ”„ PyTorch ì™„ì „ ì¬ì„¤ì¹˜ ì‹œì‘...\")\n",
    "\n",
    "# 1. ê¸°ì¡´ PyTorch ì™„ì „ ì œê±°\n",
    "print(\"1ï¸âƒ£ ê¸°ì¡´ PyTorch ì œê±° ì¤‘...\")\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# 2. ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬\n",
    "print(\"\\n2ï¸âƒ£ ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ì¤‘...\")\n",
    "!pip cache purge\n",
    "\n",
    "# 3. PyTorch ì¬ì„¤ì¹˜ (CUDA 11.8 ë²„ì „)\n",
    "print(\"\\n3ï¸âƒ£ PyTorch ì¬ì„¤ì¹˜ ì¤‘...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# 4. ì„¤ì¹˜ í™•ì¸\n",
    "print(\"\\n4ï¸âƒ£ ì„¤ì¹˜ í™•ì¸ ì¤‘...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"âœ… PyTorch ë²„ì „: {torch.__version__}\")\n",
    "    print(f\"âœ… TorchVision ë²„ì „: {torchvision.__version__}\")\n",
    "    print(f\"âœ… CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "    print(f\"âœ… CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # torch._dynamo í™•ì¸\n",
    "    try:\n",
    "        import torch._dynamo\n",
    "        if hasattr(torch._dynamo, 'config'):\n",
    "            print(\"âœ… torch._dynamo.config ì •ìƒ ì ‘ê·¼ ê°€ëŠ¥\")\n",
    "        else:\n",
    "            print(\"âš ï¸  torch._dynamo.config ì†ì„± ì—†ìŒ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  torch._dynamo ì ‘ê·¼ ë¬¸ì œ: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PyTorch ì„¤ì¹˜ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"1. ëŸ°íƒ€ì„ ì¬ì‹œì‘ (ê¶Œì¥)\")\n",
    "print(\"2. í”„ë¡œì íŠ¸ ë‹¤ì‹œ í´ë¡ \")\n",
    "print(\"3. í•™ìŠµ ì½”ë“œ ì¬ì‹¤í–‰\")\n",
    "print(\"4. ì—¬ì „íˆ ë¬¸ì œ ì‹œ ìˆœí™˜ import í™•ì¸ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•ˆì „í•œ Import ìˆœì„œë¡œ í•™ìŠµ ì‹¤í–‰ (ìˆœí™˜ import ë°©ì§€)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "print(\"ğŸ›¡ï¸  ì•ˆì „í•œ Import ìˆœì„œë¡œ í•™ìŠµ ì‹¤í–‰\")\n",
    "\n",
    "# 1. í™˜ê²½ ì´ˆê¸°í™”\n",
    "print(\"1ï¸âƒ£ í™˜ê²½ ì´ˆê¸°í™” ì¤‘...\")\n",
    "os.environ['PYTHONDONTWRITEBYTECODE'] = '1'\n",
    "gc.collect()\n",
    "\n",
    "# 2. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "project_dir = '/content/sprint-ai03-team04/worktree/wooseok'\n",
    "os.chdir(project_dir)\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "print(f\"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# 3. ì•ˆì „í•œ ìˆœì„œë¡œ ëª¨ë“ˆ Import\n",
    "print(\"\\n2ï¸âƒ£ ì•ˆì „í•œ ìˆœì„œë¡œ ëª¨ë“ˆ Import ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    # ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¨¼ì €\n",
    "    print(\"  ğŸ”¹ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ import...\")\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤ ìˆœì„œëŒ€ë¡œ\n",
    "    print(\"  ğŸ”¹ config ëª¨ë“ˆ import...\")\n",
    "    from config import cfg\n",
    "    \n",
    "    print(\"  ğŸ”¹ dataset ëª¨ë“ˆ import...\")\n",
    "    from dataset import PillDetectionDataset, create_colab_dataset\n",
    "    \n",
    "    print(\"  ğŸ”¹ model ëª¨ë“ˆ import...\")\n",
    "    from models.yolo_model import create_model\n",
    "    \n",
    "    print(\"  ğŸ”¹ trainer ëª¨ë“ˆ import...\")\n",
    "    from trainer import Trainer\n",
    "    \n",
    "    print(\"  ğŸ”¹ train ëª¨ë“ˆ import...\")\n",
    "    from train import train_with_dataset\n",
    "    \n",
    "    print(\"âœ… ëª¨ë“  ëª¨ë“ˆ import ì„±ê³µ\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ğŸ”„ ê¶Œì¥ ì¡°ì¹˜:\")\n",
    "    print(\"1. ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "    print(\"2. PyTorch ì¬ì„¤ì¹˜\")\n",
    "    print(\"3. í”„ë¡œì íŠ¸ íŒŒì¼ í™•ì¸\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 4. ì•ˆì „í•œ ì„¤ì •\n",
    "print(\"\\n3ï¸âƒ£ ì•ˆì „í•œ ì„¤ì • ì ìš© ì¤‘...\")\n",
    "try:\n",
    "    # ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ë³€ê²½\n",
    "    cfg.BATCH_SIZE = 2\n",
    "    cfg.NUM_WORKERS = 0\n",
    "    cfg.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    print(f\"âœ… ë°°ì¹˜ í¬ê¸°: {cfg.BATCH_SIZE}\")\n",
    "    print(f\"âœ… Worker ìˆ˜: {cfg.NUM_WORKERS}\")\n",
    "    print(f\"âœ… ë””ë°”ì´ìŠ¤: {cfg.DEVICE}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì„¤ì • ì ìš© ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 5. ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
    "print(\"\\n4ï¸âƒ£ ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •...\")\n",
    "DATASET_JSON = \"/content/drive/MyDrive/your_dataset/train.json\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "DATASET_IMAGES = \"/content/drive/MyDrive/your_dataset/images/train\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "print(f\"ğŸ“Š JSON íŒŒì¼: {DATASET_JSON}\")\n",
    "print(f\"ğŸ–¼ï¸  ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {DATASET_IMAGES}\")\n",
    "\n",
    "# 6. í•™ìŠµ ì‹¤í–‰ (ì•ˆì „ ëª¨ë“œ)\n",
    "print(\"\\n5ï¸âƒ£ í•™ìŠµ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"1. ìœ„ì˜ ê²½ë¡œë¥¼ ì‹¤ì œ ë°ì´í„°ì…‹ ê²½ë¡œë¡œ ë³€ê²½\")\n",
    "print(\"2. ì•„ë˜ ì½”ë“œ ì£¼ì„ í•´ì œí•˜ì—¬ í•™ìŠµ ì‹¤í–‰\")\n",
    "\n",
    "# ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ë©´ í•™ìŠµ ì‹¤í–‰\n",
    "\"\"\"\n",
    "try:\n",
    "    # ë°ì´í„°ì…‹ ìƒì„±\n",
    "    dataset = create_colab_dataset(\n",
    "        json_path=DATASET_JSON,\n",
    "        img_dir=DATASET_IMAGES\n",
    "    )\n",
    "    \n",
    "    if dataset is not None:\n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ: {len(dataset)} ìƒ˜í”Œ\")\n",
    "        \n",
    "        # í•™ìŠµ ì‹¤í–‰\n",
    "        print(\"ğŸš€ ì•ˆì „ ëª¨ë“œë¡œ í•™ìŠµ ì‹œì‘...\")\n",
    "        train_with_dataset(dataset)\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ í•™ìŠµ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ë””ë²„ê¹… ë° ìˆ˜ì • ì½”ë“œ\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def fix_cuda_memory_error():\n",
    "    \"\"\"CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ ì¢…í•© ì†”ë£¨ì…˜\"\"\"\n",
    "    print(\"ğŸ”§ CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ í•´ê²° ì¤‘...\")\n",
    "    \n",
    "    # 1. GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"âœ… GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    \n",
    "    # 2. ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "    print(\"âœ… CUDA ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”\")\n",
    "    \n",
    "    # 3. GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "        allocated_memory = torch.cuda.memory_allocated(device)\n",
    "        cached_memory = torch.cuda.memory_reserved(device)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
    "        print(f\"ì´ ë©”ëª¨ë¦¬: {total_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"ìºì‹œëœ ë©”ëª¨ë¦¬: {cached_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {(total_memory - allocated_memory) / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # 4. ê¶Œì¥ ì„¤ì • ì¶œë ¥\n",
    "    print(f\"\\nâš™ï¸  ê¶Œì¥ ì„¤ì •:\")\n",
    "    print(f\"ë°°ì¹˜ í¬ê¸°: 4 ì´í•˜ (í˜„ì¬ A100-40GB ê¸°ì¤€)\")\n",
    "    print(f\"Worker ìˆ˜: 0-2 (Colab í™˜ê²½)\")\n",
    "    print(f\"Mixed precision: ì‚¬ìš© ê¶Œì¥\")\n",
    "\n",
    "def create_safe_config():\n",
    "    \"\"\"ì•ˆì „í•œ í•™ìŠµ ì„¤ì • ìƒì„±\"\"\"\n",
    "    print(\"ğŸ›¡ï¸  ì•ˆì „í•œ í•™ìŠµ ì„¤ì • ìƒì„±...\")\n",
    "    \n",
    "    # config.py ìˆ˜ì •ì„ ìœ„í•œ ì•ˆì „í•œ ê°’ë“¤\n",
    "    safe_config = {\n",
    "        'BATCH_SIZE': 2,          # ë°°ì¹˜ í¬ê¸° ëŒ€í­ ê°ì†Œ\n",
    "        'NUM_WORKERS': 0,         # Worker ìˆ˜ 0ìœ¼ë¡œ ì„¤ì •\n",
    "        'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'MIXED_PRECISION': True,  # Mixed precision í™œì„±í™”\n",
    "        'GRADIENT_CLIP': 1.0,     # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ“‹ ì•ˆì „í•œ ì„¤ì •ê°’:\")\n",
    "    for key, value in safe_config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return safe_config\n",
    "\n",
    "def test_simple_tensor_operations():\n",
    "    \"\"\"ê°„ë‹¨í•œ í…ì„œ ì—°ì‚°ìœ¼ë¡œ CUDA ìƒíƒœ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ§ª CUDA ìƒíƒœ í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸\n",
    "            device = torch.device('cuda')\n",
    "            x = torch.randn(10, 10).to(device)\n",
    "            y = torch.randn(10, 10).to(device)\n",
    "            z = torch.mm(x, y)\n",
    "            print(\"âœ… ê¸°ë³¸ CUDA í…ì„œ ì—°ì‚° ì •ìƒ\")\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ í•´ì œ\n",
    "            del x, y, z\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ CUDA ì‚¬ìš© ë¶ˆê°€\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CUDA í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸš¨ CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜ í•´ê²° ì‹œì‘\")\n",
    "fix_cuda_memory_error()\n",
    "safe_config = create_safe_config()\n",
    "cuda_test_passed = test_simple_tensor_operations()\n",
    "\n",
    "if cuda_test_passed:\n",
    "    print(\"\\nâœ… CUDA ìƒíƒœ ì •ìƒ - ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ ì¬ì‹œë„ ê°€ëŠ¥\")\n",
    "else:\n",
    "    print(\"\\nâŒ CUDA ìƒíƒœ ë¶ˆì•ˆì • - ëŸ°íƒ€ì„ ì¬ì‹œì‘ ê¶Œì¥\")\n",
    "    \n",
    "print(\"\\nğŸ”„ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"1. ëŸ°íƒ€ì„ ì¬ì‹œì‘ (í•„ìš”ì‹œ)\")\n",
    "print(\"2. ë°°ì¹˜ í¬ê¸°ë¥¼ 2ë¡œ ì„¤ì •\")\n",
    "print(\"3. NUM_WORKERSë¥¼ 0ìœ¼ë¡œ ì„¤ì •\")\n",
    "print(\"4. í•™ìŠµ ì¬ì‹œë„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84783eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA ì˜¤ë¥˜ í•´ê²° í›„ ì•ˆì „í•œ í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # ë””ë²„ê¹… ëª¨ë“œ\n",
    "os.chdir('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "sys.path.append('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "\n",
    "# 2. GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# 3. ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ config ì„ì‹œ ìˆ˜ì •\n",
    "try:\n",
    "    from config import cfg\n",
    "    \n",
    "    # ì›ë³¸ ì„¤ì • ë°±ì—…\n",
    "    original_batch_size = cfg.BATCH_SIZE\n",
    "    original_num_workers = cfg.NUM_WORKERS\n",
    "    \n",
    "    # ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ì„ì‹œ ë³€ê²½\n",
    "    cfg.BATCH_SIZE = 2          # ë°°ì¹˜ í¬ê¸° ëŒ€í­ ê°ì†Œ\n",
    "    cfg.NUM_WORKERS = 0         # Worker ìˆ˜ 0ìœ¼ë¡œ ì„¤ì •\n",
    "    cfg.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    print(\"âš™ï¸  ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ë³€ê²½:\")\n",
    "    print(f\"ë°°ì¹˜ í¬ê¸°: {original_batch_size} â†’ {cfg.BATCH_SIZE}\")\n",
    "    print(f\"Worker ìˆ˜: {original_num_workers} â†’ {cfg.NUM_WORKERS}\")\n",
    "    print(f\"ë””ë°”ì´ìŠ¤: {cfg.DEVICE}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 4. ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½)\n",
    "DATASET_JSON = \"/content/drive/MyDrive/your_dataset/train.json\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "DATASET_IMAGES = \"/content/drive/MyDrive/your_dataset/images/train\"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "# 5. ì•ˆì „í•œ í•™ìŠµ ì‹¤í–‰\n",
    "try:\n",
    "    print(\"ğŸš€ ì•ˆì „í•œ í•™ìŠµ ì‹œì‘...\")\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ìƒì„±\n",
    "    from dataset import create_colab_dataset\n",
    "    dataset = create_colab_dataset(\n",
    "        json_path=DATASET_JSON,\n",
    "        img_dir=DATASET_IMAGES\n",
    "    )\n",
    "    \n",
    "    if dataset is not None:\n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ: {len(dataset)} ìƒ˜í”Œ\")\n",
    "        \n",
    "        # ì•ˆì „í•œ í•™ìŠµ ì‹¤í–‰\n",
    "        from train import train_with_dataset\n",
    "        \n",
    "        # ì¶”ê°€ ì•ˆì „ ì¥ì¹˜\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        print(\"ğŸ›¡ï¸  ì•ˆì „ ëª¨ë“œë¡œ í•™ìŠµ ì‹œì‘...\")\n",
    "        train_with_dataset(dataset)\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨\")\n",
    "        print(\"ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "        print(f\"JSON: {DATASET_JSON}\")\n",
    "        print(f\"Images: {DATASET_IMAGES}\")\n",
    "        \n",
    "except RuntimeError as e:\n",
    "    if \"CUDA\" in str(e):\n",
    "        print(f\"âŒ CUDA ì˜¤ë¥˜ ì¬ë°œìƒ: {e}\")\n",
    "        print(\"\\nğŸ”„ ê¶Œì¥ ì¡°ì¹˜:\")\n",
    "        print(\"1. ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "        print(\"2. ë°°ì¹˜ í¬ê¸°ë¥¼ 1ë¡œ ë” ì¤„ì´ê¸°\")\n",
    "        print(\"3. CPU ëª¨ë“œë¡œ ì „í™˜ (cfg.DEVICE = 'cpu')\")\n",
    "    else:\n",
    "        print(f\"âŒ ê¸°íƒ€ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "finally:\n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"ğŸ§¹ í•™ìŠµ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd625c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš¨ ê¸´ê¸‰ ëŒ€ì•ˆ: CPU ì „ìš© í•™ìŠµ (CUDA ì˜¤ë¥˜ ì§€ì† ì‹œ)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"ğŸ”„ CPU ì „ìš© ëª¨ë“œë¡œ ì „í™˜...\")\n",
    "\n",
    "# 1. CUDA ì™„ì „ ë¹„í™œì„±í™”\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "torch.cuda.is_available = lambda: False\n",
    "\n",
    "# 2. í”„ë¡œì íŠ¸ ì„¤ì •\n",
    "os.chdir('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "sys.path.append('/content/sprint-ai03-team04/worktree/wooseok')\n",
    "\n",
    "# 3. CPU ì „ìš© ì„¤ì •\n",
    "try:\n",
    "    from config import cfg\n",
    "    \n",
    "    cfg.DEVICE = 'cpu'\n",
    "    cfg.BATCH_SIZE = 4          # CPUì—ì„œëŠ” ë°°ì¹˜ í¬ê¸° ì¡°ê¸ˆ ëŠ˜ë ¤ë„ ë¨\n",
    "    cfg.NUM_WORKERS = 2         # CPUì—ì„œëŠ” worker ì‚¬ìš© ê°€ëŠ¥\n",
    "    cfg.EPOCHS = 2              # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì—í¬í¬ ìˆ˜ ì¤„ì´ê¸°\n",
    "    \n",
    "    print(\"ğŸ’» CPU ì „ìš© ì„¤ì •:\")\n",
    "    print(f\"ë””ë°”ì´ìŠ¤: {cfg.DEVICE}\")\n",
    "    print(f\"ë°°ì¹˜ í¬ê¸°: {cfg.BATCH_SIZE}\")\n",
    "    print(f\"Worker ìˆ˜: {cfg.NUM_WORKERS}\")\n",
    "    print(f\"ì—í¬í¬: {cfg.EPOCHS}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 4. CPU ì „ìš© í•™ìŠµ ì‹¤í–‰\n",
    "print(\"\\nâš ï¸  ì£¼ì˜: CPU ëª¨ë“œëŠ” ë§¤ìš° ëŠë¦½ë‹ˆë‹¤ (í…ŒìŠ¤íŠ¸ ëª©ì )\")\n",
    "print(\"ì‹¤ì œ í•™ìŠµì€ CUDA ì˜¤ë¥˜ í•´ê²° í›„ GPUì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "\n",
    "# ì‚¬ìš©ì í™•ì¸\n",
    "print(\"\\nğŸ¤” CPU ëª¨ë“œë¡œ ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\")\n",
    "print(\"ê³„ì†í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "\n",
    "# ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ë©´ CPU ëª¨ë“œë¡œ ì‹¤í–‰\n",
    "\"\"\"\n",
    "try:\n",
    "    # ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
    "    DATASET_JSON = \"/content/drive/MyDrive/your_dataset/train.json\"\n",
    "    DATASET_IMAGES = \"/content/drive/MyDrive/your_dataset/images/train\"\n",
    "    \n",
    "    from dataset import create_colab_dataset\n",
    "    dataset = create_colab_dataset(\n",
    "        json_path=DATASET_JSON,\n",
    "        img_dir=DATASET_IMAGES\n",
    "    )\n",
    "    \n",
    "    if dataset is not None:\n",
    "        print(f\"âœ… ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ: {len(dataset)} ìƒ˜í”Œ\")\n",
    "        \n",
    "        from train import train_with_dataset\n",
    "        print(\"ğŸ’» CPU ëª¨ë“œë¡œ í•™ìŠµ ì‹œì‘... (ë§¤ìš° ëŠë¦¼)\")\n",
    "        train_with_dataset(dataset)\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ CPU í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ¯ ê¶Œì¥ í•´ê²°ì±…:\")\n",
    "print(\"1. ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "print(\"2. GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œë„\")\n",
    "print(\"3. ë°°ì¹˜ í¬ê¸°ë¥¼ 1ë¡œ ì„¤ì •\")\n",
    "print(\"4. ì´ì „ ì…€ì˜ 'ì•ˆì „í•œ í•™ìŠµ ì‹¤í–‰' ì½”ë“œ ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ada6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ìš©í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import psutil\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "def check_system_resources():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸\"\"\"\n",
    "    print(\"=== ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í˜„í™© ===\")\n",
    "    \n",
    "    # CPU ë° ë©”ëª¨ë¦¬\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    memory = psutil.virtual_memory()\n",
    "    \n",
    "    print(f\"ğŸ–¥ï¸  CPU ì‚¬ìš©ëŸ‰: {cpu_percent}%\")\n",
    "    print(f\"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory.percent}%\")\n",
    "    print(f\"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {memory.available / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # GPU ì •ë³´\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "        gpu_allocated = torch.cuda.memory_allocated(0)\n",
    "        gpu_cached = torch.cuda.memory_reserved(0)\n",
    "        \n",
    "        print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ğŸ“ˆ GPU ë©”ëª¨ë¦¬ ì´ëŸ‰: {gpu_memory / (1024**3):.2f} GB\")\n",
    "        print(f\"ğŸ”¢ GPU í• ë‹¹ëœ ë©”ëª¨ë¦¬: {gpu_allocated / (1024**3):.2f} GB\")\n",
    "        print(f\"ğŸ’½ GPU ìºì‹œëœ ë©”ëª¨ë¦¬: {gpu_cached / (1024**3):.2f} GB\")\n",
    "    else:\n",
    "        print(\"âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "def save_model_to_drive(model_path, drive_path):\n",
    "    \"\"\"ëª¨ë¸ì„ Google Driveì— ì €ì¥\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(drive_path):\n",
    "            os.makedirs(drive_path)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path = os.path.join(drive_path, f\"model_{timestamp}.pth\")\n",
    "        \n",
    "        shutil.copy2(model_path, save_path)\n",
    "        print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_gpu_cache():\n",
    "    \"\"\"GPU ìºì‹œ ì •ë¦¬\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"ğŸ§¹ GPU ìºì‹œ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "def quick_dataset_check(json_path, img_dir):\n",
    "    \"\"\"ë°ì´í„°ì…‹ ë¹ ë¥¸ í™•ì¸\"\"\"\n",
    "    print(\"=== ë°ì´í„°ì…‹ ë¹ ë¥¸ í™•ì¸ ===\")\n",
    "    \n",
    "    # JSON íŒŒì¼ í™•ì¸\n",
    "    if os.path.exists(json_path):\n",
    "        print(f\"âœ… JSON íŒŒì¼ ì¡´ì¬: {json_path}\")\n",
    "        \n",
    "        import json\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"ğŸ“Š ì´ë¯¸ì§€ ê°œìˆ˜: {len(data['images'])}\")\n",
    "            print(f\"ğŸ·ï¸  ì–´ë…¸í…Œì´ì…˜ ê°œìˆ˜: {len(data['annotations'])}\")\n",
    "            print(f\"ğŸ¯ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜: {len(data['categories'])}\")\n",
    "    else:\n",
    "        print(f\"âŒ JSON íŒŒì¼ ì—†ìŒ: {json_path}\")\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "    if os.path.exists(img_dir):\n",
    "        img_count = len([f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\"âœ… ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì¡´ì¬: {img_dir}\")\n",
    "        print(f\"ğŸ–¼ï¸  ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {img_count}\")\n",
    "    else:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì—†ìŒ: {img_dir}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "print(\"ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(\"ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤:\")\n",
    "print(\"- check_system_resources(): ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸\")\n",
    "print(\"- save_model_to_drive(model_path, drive_path): ëª¨ë¸ Drive ì €ì¥\")\n",
    "print(\"- clean_gpu_cache(): GPU ìºì‹œ ì •ë¦¬\")\n",
    "print(\"- quick_dataset_check(json_path, img_dir): ë°ì´í„°ì…‹ ë¹ ë¥¸ í™•ì¸\")\n",
    "\n",
    "# í˜„ì¬ ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸\n",
    "check_system_resources()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
